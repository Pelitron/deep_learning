{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 2. Modelo híbrido con PyTorch\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, metadata_input_size):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.image_model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "        self.image_model.classifier = nn.Sequential(\n",
        "            nn.Linear(self.image_model.classifier[1].in_features, 64), #128\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.3) #Sin Drop out funciona mejor\n",
        "        )\n",
        "\n",
        "        self.metadata_fc = nn.Sequential(\n",
        "            nn.Linear(metadata_input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2) #0.3, 0.2,0.1 0,2 es el mejor valor\n",
        "        )\n",
        "\n",
        "        self.combined_fc = nn.Sequential(\n",
        "            nn.Linear(192, 64), #256\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),#0.3, 0.2, 0.1. 0,2 es el mejor valor\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, image, metadata):\n",
        "        image_features = self.image_model(image)\n",
        "        metadata_features = self.metadata_fc(metadata)\n",
        "        combined = torch.cat((image_features, metadata_features), dim=1)\n",
        "        output = self.combined_fc(combined)\n",
        "        return output"
      ],
      "metadata": {
        "id": "v896jYfzX6AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Punto 2 version 2.1\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, metadata_input_size):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.image_model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "        # Modificar la capa de entrada para aceptar imágenes de 128x128\n",
        "        self.image_model.features[0][0] = nn.Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "\n",
        "        self.image_model.classifier = nn.Sequential(\n",
        "            nn.Linear(self.image_model.classifier[1].in_features, 64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.metadata_fc = nn.Sequential(\n",
        "            nn.Linear(metadata_input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        self.combined_fc = nn.Sequential(\n",
        "            nn.Linear(192, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, image, metadata):\n",
        "        image_features = self.image_model(image)\n",
        "        metadata_features = self.metadata_fc(metadata)\n",
        "        combined = torch.cat((image_features, metadata_features), dim=1)\n",
        "        output = self.combined_fc(combined)\n",
        "        return output"
      ],
      "metadata": {
        "id": "K18-jjyNnlw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicando cambios anteriores más finetuning\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, metadata_input_size):\n",
        "        super(HybridModel, self).__init__()\n",
        "        # Cargar EfficientNet-B0 con pesos preentrenados\n",
        "        self.image_model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "        # Modificar la capa inicial para aceptar imágenes de tamaño 128x128\n",
        "        self.image_model.features[0][0] = nn.Conv2d(\n",
        "            in_channels=3, out_channels=32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
        "        )\n",
        "\n",
        "        # Ajustar el clasificador para reducir la dimensionalidad\n",
        "        self.image_model.classifier = nn.Sequential(\n",
        "            nn.Linear(self.image_model.classifier[1].in_features, 64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Bloque para procesar los metadatos\n",
        "        self.metadata_fc = nn.Sequential(\n",
        "            nn.Linear(metadata_input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # Capa combinada para salida final\n",
        "        self.combined_fc = nn.Sequential(\n",
        "            nn.Linear(192, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Fine-tuning: Congelar las capas iniciales de EfficientNet\n",
        "        for param in self.image_model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Descongelar el clasificador para permitir entrenamiento\n",
        "        for param in self.image_model.classifier.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, image, metadata):\n",
        "        # Extracción de características de la imagen\n",
        "        image_features = self.image_model(image)\n",
        "        # Procesamiento de los metadatos\n",
        "        metadata_features = self.metadata_fc(metadata)\n",
        "        # Combinación de ambas características\n",
        "        combined = torch.cat((image_features, metadata_features), dim=1)\n",
        "        # Predicción final\n",
        "        output = self.combined_fc(combined)\n",
        "        return output"
      ],
      "metadata": {
        "id": "sYZG6mRwO4Up"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}